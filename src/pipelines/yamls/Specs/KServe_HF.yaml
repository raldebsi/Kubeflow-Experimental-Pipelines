apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "{serviceName}"
  namespace: "{modelNamespace}"
  annotations:
    "sidecar.istio.io/inject": "false"
spec:
  predictor:
    pytorch:
      storageUri: "pvc://{volumeResourceName}/{experimentName}"
      # containers:
      #   image: image-with-torchserve-nltk-etc

      # storageUri: "pvc://{volumeResourceName}/{experimentName}/outputs/{datasetName}"